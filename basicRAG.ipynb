{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_json(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"Data successfully loaded from {filename}\")\n",
    "        return data\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while loading data from {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from sets_reviews.json\n"
     ]
    }
   ],
   "source": [
    "lego_doc = load_from_json(\"sets_reviews.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setID': 49041, 'number': '10359', 'numberVariant': 1, 'name': '{?}', 'year': 2025, 'theme': 'Icons', 'themeGroup': 'Model making', 'category': 'Normal', 'released': False, 'image': {}, 'bricksetURL': 'https://brickset.com/sets/10359-1', 'collection': {}, 'collections': {'wantedBy': 135}, 'LEGOCom': {'US': {}, 'UK': {}, 'CA': {}, 'DE': {}}, 'rating': 0.0, 'reviewCount': 0, 'packagingType': '{Not specified}', 'availability': '{Not specified}', 'instructionsCount': 0, 'additionalImageCount': 0, 'ageRange': {}, 'dimensions': {}, 'barcode': {}, 'extendedData': {}, 'lastUpdated': '2024-03-04T15:05:35.09Z'}\n"
     ]
    }
   ],
   "source": [
    "# Flattening the structure\n",
    "flattened_lego_doc = []\n",
    "\n",
    "for year, sets in lego_doc.items():\n",
    "    flattened_lego_doc.extend(sets)\n",
    "\n",
    "print(flattened_lego_doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setID': 33706, 'number': '60335', 'numberVariant': 1, 'name': 'Train Station', 'year': 2022, 'theme': 'City', 'themeGroup': 'Modern day', 'subtheme': 'Trains', 'category': 'Normal', 'released': True, 'pieces': 907, 'minifigs': 6, 'image': {'thumbnailURL': 'https://images.brickset.com/sets/small/60335-1.jpg', 'imageURL': 'https://images.brickset.com/sets/images/60335-1.jpg'}, 'bricksetURL': 'https://brickset.com/sets/60335-1', 'collection': {}, 'collections': {'ownedBy': 3028, 'wantedBy': 1933}, 'LEGOCom': {'US': {'retailPrice': 99.99, 'dateFirstAvailable': '2022-07-26T00:00:00Z'}, 'UK': {'retailPrice': 69.99, 'dateFirstAvailable': '2022-06-01T00:00:00Z'}, 'CA': {'retailPrice': 129.99, 'dateFirstAvailable': '2022-07-26T00:00:00Z'}, 'DE': {'retailPrice': 79.99, 'dateFirstAvailable': '2022-08-04T00:00:00Z'}}, 'rating': 4.3, 'reviewCount': 1, 'packagingType': 'Box', 'availability': 'Retail', 'instructionsCount': 7, 'additionalImageCount': 10, 'ageRange': {'min': 7}, 'dimensions': {'height': 28.0, 'width': 53.5, 'depth': 10.2, 'weight': 1.919}, 'barcode': {'EAN': '5702017189727', 'UPC': '673419361897'}, 'extendedData': {'tags': ['Atm', 'Baked Goods', 'Bathroom', 'Bench', 'Bicycle', 'Bird', 'Brick Built Tree', 'Brick Separator', 'Build Together', 'Bus', 'Cherry Picker', 'Coffee Machine', 'Disability', 'Feces', 'Fresh Brand', 'Level Crossing', 'Map', 'Portable Toilet', 'Public Transport', 'Railway Building', 'Railway Maintenance', 'Restaurant', 'Road System', 'Shop', 'Ticket Counter', 'Trackside Structure', 'Trailer', 'Train Station', 'Train Track'], 'description': '<p>This LEGO&reg; City Train Station (60335) set is packed with cool features, including a ticket office, coffee bar, control room, platform and a track piece that&rsquo;s compatible with LEGO City train sets. Kids also get a toy bus, road-and-rail cherry-picker truck with a portable toilet in tow, plus a grade crossing with a LEGO City Road Plate for connection to other City sets. Just add the 6 minifigure characters and let the adventures begin.</p>\\n\\n<p>Build-and-play fun for kids aged 7 and up<br />\\nThis Train Station playset comes with easy-to-follow building instructions for each model, so kids can choose to build their own LEGO toys or join friends and family members for a fun group building experience.</p>\\n\\n<p>Exploring the world through play<br />\\nLEGO City playsets put kids at the heart of the action with realistic vehicles, feature-rich structures and inspiring characters for fun role play that&rsquo;s based on real-life scenarios.</p>\\n\\n<ul>\\n\\t<li>Multi-model toy Train Station &ndash; Set the scene for imaginative play with this LEGO&reg; City Train Station (60335) playset for kids aged 7 and up</li>\\n\\t<li>All kids need to build a toy train terminal &ndash; Includes a bus, rail truck, trailer, portable toilet, Road-Plate grade crossing that connects to other LEGO&reg; sets, 4 track pieces and 6 minifigures</li>\\n\\t<li>Features and functions &ndash; The road-and-rail maintenance truck comes with fold-down wheels for traveling on the tracks, while the bus has an accessible interior with seating for 6 minifigures</li>\\n\\t<li>A fun gift idea &ndash; This playset can be given as a birthday, holiday or any-other-day gift for kids and train enthusiasts aged 7 and up</li>\\n\\t<li>Dimensions &ndash; When built, the toy Train Station measures over 8 in. (21 cm) high, 14.5 in. (37 cm) wide and 4.5 in. (12 cm) deep</li>\\n\\t<li>Includes fun minifigure accessories &ndash; This LEGO&reg; City playset comes with a toy bike, hammer, shovel, broom, screwdriver, mug and ticket tile</li>\\n\\t<li>Designed for ages 7 and up &ndash; This toy Train Stationplayset includes easy-to-follow printed building instructions for each model</li>\\n\\t<li>Learning kids through play &ndash; LEGO&reg; City building sets come with structures, vehicles and characters that inspire creativity and skill-building play</li>\\n\\t<li>Premium-quality toys &ndash; All LEGO&reg; components meet strict industry standards to ensure they are consistent, compatible and fun to build with: it&rsquo;s been that way since 1958</li>\\n\\t<li>Putting safety first &ndash; LEGO&reg; bricks and pieces are dropped, heated, crushed, twisted and analyzed to make sure they meet stringent global standards for safety</li>\\n</ul>\\n'}, 'lastUpdated': '2022-06-22T05:34:15.48Z', 'reviews': [{'author': 'chief7575', 'datePosted': '2022-11-14T20:43:20.68Z', 'rating': {'overall': 4, 'parts': 4, 'buildingExperience': 3, 'playability': 5, 'valueForMoney': 4}, 'title': 'New Train Station with poo truck - a hit with the family!', 'review': '<p>As an avid fan of trains, I was excited to see a new station was available in 2022.&nbsp; The last stations were available in 2014 #60050 (423 pieces, $65US) and prior to that 2010&#39;s offering #7937 (361 pieces, $50).&nbsp; I was not collecting LEGO at that time and eventually acquired them on the aftermarket a few years ago for a higher price, due to wanting a sealed box for each.&nbsp;&nbsp;This year&#39;s set consists of 907 pieces and costs $100.&nbsp;&nbsp;</p>\\r\\n\\r\\n<p>I feel that comparing this year to prior offerings will give a sense of value over the past dozen years.&nbsp; Comparing just station vs station - you can see from the pictures below, they are roughly the same size.&nbsp; Each came with 4 pieces of railroad track as well.&nbsp; The 2014 set has a larger platform, but about the same size of structure when compared to 2022.&nbsp; 2010 was much smaller and was mostly built to accommodate the extensive staircases/platform to cross the track.&nbsp; The prior 2 stations, both came with a small yellow taxi.&nbsp; This years set, comes with a bus, a rail truck, tow sled with port-a-potty and a road plate with manual crossing lights/barriers.</p>\\r\\n\\r\\n<p>[img]https://i.imgur.com/2aY3P3O.jpg[/img]</p>\\r\\n\\r\\n<p>[img]https://i.imgur.com/DHcKAEB.jpg[/img]</p>\\r\\n\\r\\n<p>This year&#39;s design/color scheme definitely was made to match a few of this year&#39;s other town/city set offerings, which include the #60347 Grocery Store, #60345 Farmers Market Van &amp; #60337 Express Passenger Train.&nbsp; All of them have the green/white/teal colour schemes and have references to &quot;Fresh&quot; grocery store branding.&nbsp;&nbsp;</p>\\r\\n\\r\\n<p>Functionally, the new set does not have an overhang over the tracks - which is done on purpose, as the new freight train #60336 has a car transporter that is much taller than standard train cars have been built!&nbsp; This particular train car would definitely smash into the prior 2 iterations of these train stations from earlier years.&nbsp; It does have a nice wheelchair accessible ramp, a bike rack and the standard ticket counter and snack bar/caf&eacute;.&nbsp; Plus a second level control tower.&nbsp; Also, as a wonderful bonus, there is a new street plate and attachments.&nbsp; Also included in the build, are&nbsp;the manual crossing gates that you can raise/lower on each side of the tracks.&nbsp; They are secured with a technic friction pin, so they will stay at whatever angle you want them at and not fall closed.&nbsp;&nbsp;</p>\\r\\n\\r\\n<p>The overall look to this year&#39;s station is very nice!&nbsp; I love how the roof/skylights were built and flow through the whole station.&nbsp; It gives a very modern and sleek look.&nbsp; Plus, a nice bench, tree and ATM are at the far end of the platform, nearby a triangular mosaic that hangs on the wall.&nbsp; The platform as a whole, feels very sturdy when transporting it as well.&nbsp; My one minor complaint with the structure comes down to the details with the caf&eacute;!&nbsp; It&#39;s so sparse.&nbsp; ONE whole croissant is available for purchase.&nbsp; There was ample room to provide more snacks or a place to sit.&nbsp; I feel that this is a missed opportunity that the prior sets address well, for limited space.&nbsp;&nbsp;</p>\\r\\n\\r\\n<p>Another build with this set is a city bus.&nbsp; I was surprised to look back through city offerings and not really find much in the way of buses through the years!&nbsp; I have 3 others, from prior year sets, but only one of those was a standalone offering.&nbsp; The other 2 came in quite expensive, mutli-build, conglomerate city sets.&nbsp; So not exactly a cheap LEGO vehicle to acquire.</p>\\r\\n\\r\\n<p>2018 set Capital City #60200 ($150US) has a red, double-decker, sightseeing bus.&nbsp; 2013 Town Square #60026 ($120)&nbsp;has a standard red bus.&nbsp; And 2017 has&nbsp;the #60154 Bus Station ($50) bus, in yellow.&nbsp; The train bus is closest in size, to the yellow bus, though that is a few studs longer.&nbsp; But it has a nice bike rack on the back and has much easier access to play with the interior than the yellow bus, as the roof pieces come off easily, in 3 parts.&nbsp; I&#39;ve actually modified the yellow bus for my daughter, because it is so difficult to remove the top panels on that particular model.&nbsp;&nbsp;</p>\\r\\n\\r\\n<p>[img]https://i.imgur.com/2vZCWsz.jpg[/img][img]https://i.imgur.com/IKEvtn1.jpg[/img]</p>\\r\\n\\r\\n<p>The final item to build with this set, is a handy, utility, rail truck.&nbsp; The only other instance of this particular type vehicle that I could find, goes clear back to set #7936, from 2010.&nbsp; At the time, it cost $20US, but trying to find one now will cost up to $100 in some cases to find, still sealed!&nbsp; This handy truck, not only can drive on standard roads, but it has front and back rail wheels that can lower/raise in order to drive on rail tracks.&nbsp; It comes with a small lift on the back and has a small sled attachment, which carries a port-a-potty with it!&nbsp; My daughter spent endless hours playing with this and racing the &quot;poop truck&quot; around with our trains.&nbsp;&nbsp;</p>\\r\\n\\r\\n<p>The overall build is very straightforward, from the station, the bus, the rail truck and port-a-john.&nbsp; I would say that any age would enjoy putting together this set.&nbsp; Pieces are pretty standard - some new colours for a few, which is always nice, but the standout piece is the rail ramps&nbsp;- a hard to find piece (#6404467), only available in a set once before.&nbsp; And with this set, you get 2.&nbsp; They are very handy to help re-rail any of your trains/train cars, and I&#39;m glad to have multiple of this piece.&nbsp; Other handy pieces are the new wider, window/door frames and the smaller clear doors that fit into them.&nbsp; Those are a much newer part and work well when putting a side by side door that allows for wheelchair access to either the bus or the train station.</p>\\r\\n\\r\\n<p>For $100, I thought this train station has great value.&nbsp; Just getting the station by itself is probably around $50, but then you are adding in a robust bus, and the rail truck, wagon, crossings and road plate.&nbsp; Plus 6 mini figures.&nbsp; Its a great deal by todays standards.&nbsp; The best of which is the truck driver, who has reflective type coat and hard hat on!&nbsp; Those are new to us and look brilliant!&nbsp; I just wish there were a few more figures to work/use the bus/train station.&nbsp; But we have plenty in our LEGO city to fill that void.&nbsp;&nbsp;</p>\\r\\n', 'HTML': True}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(flattened_lego_doc[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# client = OpenAI(\n",
    "#     base_url='http://localhost:11434/v1/',\n",
    "#     'ollama',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"\n",
    "# Based on a record genearate 5 questions from 5 different customers who are looking \n",
    "# for a lego set recomedation. Note that customers don't always know exact lego set name\n",
    "\n",
    "# The record:\n",
    "\n",
    "# name: {name}\n",
    "# year: {year}\n",
    "# theme: {theme}\n",
    "# description: {description}\n",
    "\n",
    "# Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "# [\"question1\", \"question2\", ..., \"question5\"]\n",
    "# \"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "use context only from provided record. genearate 5 different user prompts that users might enter when searching for a lego set. \n",
    "user might not always remember exact set features \n",
    "The record:\n",
    "\n",
    "name: {name}\n",
    "year: {year}\n",
    "theme: {theme}\n",
    "description: {description}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    name = doc[\"name\"]\n",
    "    year = \"\"\n",
    "    if \"year\" in doc:\n",
    "        year = doc[\"year\"]\n",
    "    theme = doc[\"theme\"]\n",
    "    #subtheme = \"\" \n",
    "    # if \"subtheme\" in doc:\n",
    "    #     subtheme = doc[\"subtheme\"]\n",
    "    #tags = \"\" \n",
    "    description = \"\" \n",
    "    if \"extendedData\" in doc:\n",
    "        ext = doc[\"extendedData\"]\n",
    "        # if \"tags\" in doc:\n",
    "        #     tags = ''.join(doc[\"tags\"])\n",
    "        if \"description\" in ext:\n",
    "            description = ext[\"description\"]\n",
    "    # reviews = \"\"\n",
    "    # if \"reviews\" in doc:\n",
    "    #     reviews_arr = map(lambda x: x[\"review\"], doc[\"reviews\"])\n",
    "    #     reviews = '#'.join(reviews_arr)\n",
    "        \n",
    "    prompt = prompt_template.format(name = name, year = year, theme = theme, description = description)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    \"What is the name of the LEGO set with collectible minifigures from 2012?\",\\n    \"Can anyone tell me about the LEGO Series 6 minifigure box?\",\\n    \"I\\'m looking for a 2012 LEGO set that has multiple collectible figures.\",\\n    \"What LEGO collectible minifigures were released in Series 6?\",\\n    \"Where can I find a sealed box of LEGO Minifigures Series 6?\" \\n]'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_questions(flattened_lego_doc[10319])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_data = random.sample(flattened_lego_doc, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b0703133aa48d083464a4e03825ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(test_data): \n",
    "    doc_id = doc['setID']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "    questions = generate_questions(doc)\n",
    "    results[doc_id] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to groundTruth_3.json\n"
     ]
    }
   ],
   "source": [
    "# filename = 'groundTruth_3.json'\n",
    "# try:\n",
    "#     with open(filename, 'w') as f:\n",
    "#         json.dump(results, f, indent=4)\n",
    "#     print(f\"Data successfully saved to {filename}\")\n",
    "# except IOError as e:\n",
    "#     print(f\"An error occurred while saving data to {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a lego shop assistant. Answer the QUESTION based on the CONTEXT from Lego sets database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION. Return brief description of the set bsaed on the sample data use bricksetURL to provde it's link\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "   \n",
    "\n",
    "    context = \"\"\n",
    "    #+ ''.join(doc.get(\"extendedData\", \"\")) + ''.join(doc.get(\"reviews\", \"\")) \n",
    "    for doc in search_results:\n",
    "        #context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "        context = context + doc[\"name\"] + doc[\"bricksetURL\"] + str(doc[\"year\"]) + doc[\"theme\"] + doc[\"category\"] + f\"\\n\\n\"\n",
    "        if \"minifigs\" in doc:\n",
    "            context = context + str(doc[\"minifigs\"])\n",
    "        if \"themeGroup\" in doc:\n",
    "            context = context + doc[\"themeGroup\"]\n",
    "        if \"reviews\" in doc:\n",
    "            reviews_str = \"\\n\\n\".join(\n",
    "                f\"Author: {review['author']}\\nDate: {review['datePosted']}\\nTitle: {review['title']}\\nReview: {review['review']}\"\n",
    "                for review in doc[\"reviews\"]\n",
    "            )\n",
    "            context = context + reviews_str\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector based search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-mpnet-base-v2'#multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'lego_sets'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping for the index\n",
    "mapping = {\n",
    "    \"properties\": {\n",
    "        \"name_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"subtheme_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"category_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"theme_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"tags_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"description_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"review_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"year_vector\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 768,\n",
    "            \"index\": True,\n",
    "            \"similarity\": \"cosine\",\n",
    "        },\n",
    "        \"setID\": {\"type\": \"long\"},\n",
    "        \"number\": {\"type\": \"keyword\"},\n",
    "        \"numberVariant\": {\"type\": \"integer\"},\n",
    "        \"name\": {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\"}}},\n",
    "        \"year\": {\"type\": \"integer\", \"null_value\": 0},\n",
    "        \"theme\": {\"type\": \"keyword\",  \"null_value\": \"\"},\n",
    "        \"themeGroup\": {\"type\": \"keyword\",  \"null_value\": \"\"},\n",
    "        \"category\": {\"type\": \"keyword\", \"null_value\": \"\"},\n",
    "        \"released\": {\"type\": \"boolean\"},\n",
    "        \"pieces\": {\"type\": \"integer\"},\n",
    "        \"minifigs\": {\"type\": \"integer\", \"null_value\": 0},\n",
    "        \"image\": {\n",
    "            \"properties\": {\n",
    "                \"thumbnailURL\": {\"type\": \"keyword\"},\n",
    "                \"imageURL\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        },\n",
    "        \"bricksetURL\": {\"type\": \"keyword\"},\n",
    "        \"collection\": {\"type\": \"object\"},\n",
    "        \"collections\": {\n",
    "            \"properties\": {\n",
    "                \"ownedBy\": {\"type\": \"integer\"},\n",
    "                \"wantedBy\": {\"type\": \"integer\"}\n",
    "            }\n",
    "        },\n",
    "        \"LEGOCom\": {\n",
    "            \"properties\": {\n",
    "                \"US\": {\n",
    "                    \"properties\": {\n",
    "                        \"retailPrice\": {\"type\": \"float\"},\n",
    "                        \"dateFirstAvailable\": {\"type\": \"date\"},\n",
    "                        \"dateLastAvailable\": {\"type\": \"date\"}\n",
    "                    }\n",
    "                },\n",
    "                \"UK\": {\n",
    "                    \"properties\": {\n",
    "                        \"retailPrice\": {\"type\": \"float\"},\n",
    "                        \"dateFirstAvailable\": {\"type\": \"date\"},\n",
    "                        \"dateLastAvailable\": {\"type\": \"date\"}\n",
    "                    }\n",
    "                },\n",
    "                \"CA\": {\n",
    "                    \"properties\": {\n",
    "                        \"retailPrice\": {\"type\": \"float\"},\n",
    "                        \"dateFirstAvailable\": {\"type\": \"date\"},\n",
    "                        \"dateLastAvailable\": {\"type\": \"date\"}\n",
    "                    }\n",
    "                },\n",
    "                \"DE\": {\"type\": \"object\"}\n",
    "            }\n",
    "        },\n",
    "        \"rating\": {\"type\": \"float\", \"null_value\": 0.0},\n",
    "        \"reviewCount\": {\"type\": \"integer\"},\n",
    "        \"packagingType\": {\"type\": \"keyword\"},\n",
    "        \"availability\": {\"type\": \"keyword\"},\n",
    "        \"instructionsCount\": {\"type\": \"integer\"},\n",
    "        \"additionalImageCount\": {\"type\": \"integer\"},\n",
    "        \"ageRange\": {\n",
    "            \"properties\": {\n",
    "                \"min\": {\"type\": \"integer\"},\n",
    "                \"max\": {\"type\": \"integer\"}\n",
    "            }\n",
    "        },\n",
    "        \"dimensions\": {\n",
    "            \"properties\": {\n",
    "                \"height\": {\"type\": \"float\"},\n",
    "                \"width\": {\"type\": \"float\"},\n",
    "                \"depth\": {\"type\": \"float\"},\n",
    "                \"weight\": {\"type\": \"float\"}\n",
    "            }\n",
    "        },\n",
    "        \"barcode\": {\n",
    "            \"properties\": {\n",
    "                \"EAN\": {\"type\": \"keyword\"},\n",
    "                \"UPC\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        },\n",
    "        \"extendedData\": {\n",
    "            \"properties\": {\n",
    "                \"tags\": {\"type\": \"keyword\"},\n",
    "                \"description\": {\"type\": \"text\"}\n",
    "            }\n",
    "        },\n",
    "        \"lastUpdated\": {\"type\": \"date\"},\n",
    "        \"reviews\": {\n",
    "            \"type\": \"nested\",\n",
    "            \"properties\": {\n",
    "                \"author\": {\"type\": \"keyword\"},\n",
    "                \"datePosted\": {\"type\": \"date\"},\n",
    "                \"rating\": {\n",
    "                    \"properties\": {\n",
    "                        \"overall\": {\"type\": \"float\"},\n",
    "                        \"parts\": {\"type\": \"float\"},\n",
    "                        \"buildingExperience\": {\"type\": \"float\"},\n",
    "                        \"playability\": {\"type\": \"float\"},\n",
    "                        \"valueForMoney\": {\"type\": \"float\"}\n",
    "                    }\n",
    "                },\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"review\": {\"type\": \"text\"},\n",
    "                \"HTML\": {\"type\": \"boolean\"}\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "index_name = \"lego_sets\"\n",
    "\n",
    "es_client.options(ignore_status=[400,404]).indices.delete(index=index_name)\n",
    "es_client.indices.create(index=index_name, body={\"mappings\": mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from groundTruth_3.json\n"
     ]
    }
   ],
   "source": [
    "def load_from_json(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"Data successfully loaded from {filename}\")\n",
    "        return data\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while loading data from {filename}: {e}\")\n",
    "        return None\n",
    "    \n",
    "ground_truth_json = load_from_json('groundTruth_3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_keys = list(ground_truth_json.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_lego_doc_filtered = list(filter(lambda set: str(set['setID']) in truth_keys, flattened_lego_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7329597a6dc440bb13da9bc5c9fe077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(flattened_lego_doc_filtered):\n",
    "    if \"name\" in doc:\n",
    "        doc['name_vector'] = model.encode(doc[\"name\"])\n",
    "    \n",
    "    if \"theme\" in doc:\n",
    "        doc['theme_vector'] = model.encode(doc[\"theme\"])\n",
    "\n",
    "    if \"subtheme\" in doc:\n",
    "        doc['subtheme_vector'] = model.encode(doc[\"subtheme\"])\n",
    "    \n",
    "    if \"category\" in doc:\n",
    "        doc['category_vector'] = model.encode(doc[\"category\"])\n",
    "\n",
    "    if \"extendedData\" in doc:\n",
    "        if \"tags\" in doc:\n",
    "            doc['tags_vector'] = model.encode(''.join(doc[\"tags\"]))\n",
    "        if \"description\" in doc:\n",
    "            doc['description_vector'] = model.encode(doc[\"description\"])\n",
    " \n",
    "    if \"reviews\" in doc:\n",
    "        reviews_arr = map(lambda x: x[\"review\"], doc[\"reviews\"])\n",
    "        doc['review_vector'] = model.encode('#'.join(reviews_arr))\n",
    "    \n",
    "    if 'year' in doc:\n",
    "        doc['year_vector'] = model.encode(str(doc['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f9434c4cb848a1810b371c31b1d3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing documents: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 20930 documents successfully. 0 documents failed.\n"
     ]
    }
   ],
   "source": [
    "# from elasticsearch.helpers import bulk\n",
    "\n",
    "# # Function to read documents from the backup file\n",
    "# def read_documents(filename):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         for line in f:\n",
    "#             yield json.loads(line.strip())\n",
    "\n",
    "# # Function to prepare documents for bulk indexing\n",
    "# def doc_generator(documents):\n",
    "#     for doc in documents:\n",
    "#         yield {\n",
    "#             \"_index\": index_name,\n",
    "#             \"_source\": doc\n",
    "#         }\n",
    "# # Read documents from the backup file\n",
    "# documents = read_documents('lego_sets_backup.json')\n",
    "\n",
    "# # Bulk index the documents\n",
    "# success, failed = bulk(es_client, doc_generator(tqdm(documents, desc=\"Indexing documents\")), stats_only=True)\n",
    "\n",
    "# print(f\"Indexed {success} documents successfully. {failed} documents failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8036ba6a932a4fc5b0a8a595a2c7b909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(flattened_lego_doc_filtered):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(query):\n",
    "    doc = nlp(query)\n",
    "    entities = {\n",
    "        \"name\": [],\n",
    "        \"keywords\": [],\n",
    "    }\n",
    "    \n",
    "    # Extract named entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" or ent.label_ == \"PRODUCT\":\n",
    "            entities[\"name\"].append(ent.text)\n",
    "    \n",
    "    # Extract themes and tags (this is a simplistic approach, you might need to refine this)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            entities[\"keywords\"].append(token.text.lower())\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_search_parameters(query):\n",
    "    params = {\n",
    "        'user_query': query,\n",
    "        'year_from': None,\n",
    "        'year_to': None,\n",
    "        'pieces_min': None,\n",
    "        'pieces_max': None\n",
    "    }\n",
    "    \n",
    "    # Extract years\n",
    "    year_pattern = r'\\b(19\\d{2}|20\\d{2})\\b'\n",
    "    years = re.findall(year_pattern, query)\n",
    "    if years:\n",
    "        year_ints = [int(y) for y in years]\n",
    "        params['year_from'] = min(year_ints)\n",
    "        params['year_to'] = max(year_ints)\n",
    "        query = re.sub(year_pattern, '', query)\n",
    "    \n",
    "    # Extract date ranges\n",
    "    date_patterns = [\n",
    "        (r'\\b(?:from|since|after)\\s+(19\\d{2}|20\\d{2})\\b', 'year_from'),\n",
    "        (r'\\b(?:to|until|before)\\s+(19\\d{2}|20\\d{2})\\b', 'year_to'),\n",
    "        (r'\\b(?:in|during|around)\\s+(19\\d{2}|20\\d{2})\\b', 'year_specific')\n",
    "    ]\n",
    "    for pattern, param in date_patterns:\n",
    "        match = re.search(pattern, query, re.IGNORECASE)\n",
    "        if match:\n",
    "            year = int(match.group(1))\n",
    "            if param == 'year_specific':\n",
    "                params['year_from'] = year\n",
    "                params['year_to'] = year\n",
    "            else:\n",
    "                params[param] = year\n",
    "            query = re.sub(pattern, '', query, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle cases where only one year is specified\n",
    "    current_year = datetime.now().year\n",
    "    if params['year_from'] and not params['year_to']:\n",
    "        params['year_to'] = min(params['year_from'] + 5, current_year)\n",
    "    elif params['year_to'] and not params['year_from']:\n",
    "        params['year_from'] = max(1949, params['year_to'] - 5)\n",
    "    \n",
    "    # Extract piece count\n",
    "    piece_pattern = r'\\b(\\d+)(?:\\s*-\\s*(\\d+))?\\s*pieces?\\b'\n",
    "    piece_match = re.search(piece_pattern, query, re.IGNORECASE)\n",
    "    if piece_match:\n",
    "        params['pieces_min'] = int(piece_match.group(1))\n",
    "        params['pieces_max'] = int(piece_match.group(2)) if piece_match.group(2) else params['pieces_min']\n",
    "        query = re.sub(piece_pattern, '', query, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up the query\n",
    "    params['user_query'] = ' '.join(query.split())\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_elasticsearch_query(params):\n",
    "    input_embedding = model.encode(params['user_query'])\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": params['user_query'],\n",
    "                            \"fields\": [\"name\", \"theme\", \"subtheme\", \"category\"],\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"fuzziness\": \"2\",\n",
    "                            \"operator\": \"or\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                        \"query\": {\"match_all\": {}},\n",
    "                        \"script\": {\n",
    "                            \"source\": \"\"\"\n",
    "                            double score = 0.0;\n",
    "                            double vector_score = 0.0;\n",
    "                            int vector_count = 0;\n",
    "                            \n",
    "                            if (doc.containsKey('name_vector') && !doc['name_vector'].empty) {\n",
    "                                vector_score += cosineSimilarity(params.query_vector, 'name_vector');\n",
    "                                vector_count++;\n",
    "                            }\n",
    "                            if (doc.containsKey('theme_vector') && !doc['theme_vector'].empty) {\n",
    "                                vector_score += cosineSimilarity(params.query_vector, 'theme_vector');\n",
    "                                vector_count++;\n",
    "                            }\n",
    "                            if (doc.containsKey('subtheme_vector') && !doc['subtheme_vector'].empty) {\n",
    "                                vector_score += cosineSimilarity(params.query_vector, 'subtheme_vector');\n",
    "                                vector_count++;\n",
    "                            }\n",
    "                            if (doc.containsKey('description_vector') && !doc['description_vector'].empty) {\n",
    "                                vector_score += cosineSimilarity(params.query_vector, 'description_vector');\n",
    "                                vector_count++;\n",
    "                            }\n",
    "\n",
    "                            if (doc.containsKey('review_vector') && !doc['review_vector'].empty) {\n",
    "                                vector_score += cosineSimilarity(params.query_vector, 'review_vector');\n",
    "                                vector_count++;\n",
    "                            }\n",
    "                            \n",
    "                            if (vector_count > 0) {\n",
    "                                score = vector_score + 1;\n",
    "                            }\n",
    "\n",
    "                            return score;\n",
    "                            \"\"\",\n",
    "                            \"params\": {\n",
    "                                \"query_vector\": input_embedding,\n",
    "                            }\n",
    "                    }\n",
    "                    }\n",
    "                    }\n",
    "                ],\n",
    "                \"filter\": [\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"themes\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"theme.keyword\",\n",
    "                    \"size\": 10\n",
    "                }\n",
    "            },\n",
    "            \"years\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"year\",\n",
    "                    \"calendar_interval\": \"year\"\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"size\": 15\n",
    "    }\n",
    "\n",
    "    # Add year filter if specified\n",
    "    if params['year_from'] is not None or params['year_to'] is not None:\n",
    "        year_filter = {\"range\": {\"year\": {}}}\n",
    "        if params['year_from'] is not None:\n",
    "            year_filter[\"range\"][\"year\"][\"gte\"] = params['year_from']\n",
    "        if params['year_to'] is not None:\n",
    "            year_filter[\"range\"][\"year\"][\"lte\"] = params['year_to']\n",
    "        query[\"query\"][\"bool\"][\"filter\"].append(year_filter)\n",
    "\n",
    "    # Add piece count filter if specified\n",
    "    if params['pieces_min'] is not None or params['pieces_max'] is not None:\n",
    "        piece_filter = {\"range\": {\"pieces\": {}}}\n",
    "        if params['pieces_min'] is not None:\n",
    "            piece_filter[\"range\"][\"pieces\"][\"gte\"] = params['pieces_min']\n",
    "        if params['pieces_max'] is not None:\n",
    "            piece_filter[\"range\"][\"pieces\"][\"lte\"] = params['pieces_max']\n",
    "        query[\"query\"][\"bool\"][\"filter\"].append(piece_filter)\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.exceptions import ConnectionError, RequestError\n",
    "\n",
    "def elastic_search_vector(user_input):\n",
    "    doc = nlp(user_input)\n",
    "    cleaned_query = []\n",
    "    for ent in doc:\n",
    "        if ent.is_stop == False:\n",
    "            cleaned_query.append(ent.text)\n",
    "    user_input = ' '.join(cleaned_query)\n",
    "    params = extract_search_parameters(user_input) \n",
    "    es_query = build_elasticsearch_query(params)\n",
    "\n",
    "    # Execute the search query\n",
    "    try:\n",
    "        response = es_client.search(index=index_name, body=es_query)\n",
    "    except ConnectionError as e:\n",
    "        print(f\"ConnectionError during search: {e}\")\n",
    "        return str(e)\n",
    "    except RequestError as e:\n",
    "        print(f\"RequestError during search: {e}\")\n",
    "        print(\"This might be due to an invalid query structure or non-existent fields.\")\n",
    "        return f\"RequestError during search: {e}\"\n",
    "\n",
    "    result_docs = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def elastic_search(user_input):\n",
    "    # Connect to Elasticsearch\n",
    "#\"fields\": [\"name^3\", \"theme\", \"subtheme\", \"year\", \"rating\", \"themeGroup\", \"minifigs\"],\n",
    "    # Convert the extracted information into an Elasticsearch query\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": user_input,\n",
    "                \"fields\": [\"name\", \"theme\", \"subtheme\", \"theme\"],\n",
    "                \"fuzziness\": 2\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "\n",
    "    # Execute the search query\n",
    "    error_info = \"\"\n",
    "    try:\n",
    "        response = es_client.search(index=index_name, body=es_query)\n",
    "    except ConnectionError as e:\n",
    "        print(f\"ConnectionError during search: {e}\")\n",
    "        error_info = e\n",
    "        return error_info\n",
    "    except RequestError as e:\n",
    "        print(f\"RequestError during search: {e}\")\n",
    "        print(\"This might be due to an invalid query structure or non-existent fields.\")\n",
    "        error_info = f\"RequestError during search: {e}\"\n",
    "        return error_info\n",
    "    \n",
    "    result_docs = []\n",
    "\n",
    "    # Print the search results\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search_vector(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What LEGO gear item is a key light with a momentary switch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = extract_search_parameters(query)\n",
    "search_entities = extract_entities(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {'user_query': 'What LEGO gear item is a key light with a momentary switch', 'year_from': None, 'year_to': None, 'pieces_min': None, 'pieces_max': None} \n",
      "\n",
      "\n",
      " entities = {'name': [], 'keywords': ['gear', 'item', 'light', 'switch']}\n"
     ]
    }
   ],
   "source": [
    "print(f'params = {search_params} \\n\\n\\n entities = {search_entities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_query = []\n",
    "for ent in doc:\n",
    "    if ent.is_stop == False:\n",
    "        cleaned_query.append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEGO gear item key light momentary switch\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(cleaned_query)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24026 LEGO Friends Emma Key Light',\n",
       " '23106 Santa Key Light',\n",
       " '23042 2x4 Brick Key Light (Red)',\n",
       " '8398 Automatic Right Electric Switch',\n",
       " '27217 LEGO House Boy Key Chain',\n",
       " '10098 Darth Vader Flashlight',\n",
       " '4571 Light Sensor',\n",
       " '673 Ultra-Light',\n",
       " '2709 Head Wear',\n",
       " '134 Road Burner',\n",
       " '3395 Aero Hawk',\n",
       " '343 Airport Security Squad',\n",
       " '5406 1x1 Stud Light Grey',\n",
       " '24492 LEGO Ice Brick Tray Red',\n",
       " '6692 Shadow Trooper']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = elastic_search_vector(query)\n",
    "names = map(lambda x: f'{x[\"setID\"]} {x[\"name\"]}', results)\n",
    "display(list(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I recommend the **Castle Building Set**. This set features a mini castle that comes with a drawbridge, a minifigure, and some charming elements that would make an ideal backdrop for a rabbit or other whimsical creatures. While there are no specific trees included in the set, it encourages creativity, allowing you to build your own scenes.\\n\\nYou can find more details about this set here: [Castle Building Set](https://brickset.com/sets/6193-12009)'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c578630530054abb864f6679f7d417ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving documents: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index backup completed and saved to 'lego_sets_backup.json'\n"
     ]
    }
   ],
   "source": [
    "# from elasticsearch.helpers import scan\n",
    "\n",
    "# # Function to handle JSON serialization of special types\n",
    "# def json_serial(obj):\n",
    "#     if isinstance(obj, (datetime, date)):\n",
    "#         return obj.isoformat()\n",
    "#     raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "# # Scan and scroll through the index\n",
    "# results = scan(es_client, index=index_name, query={\"query\": {\"match_all\": {}}})\n",
    "\n",
    "# # Save the documents to a file\n",
    "# with open('lego_sets_backup.json', 'w') as f:\n",
    "#     for item in tqdm(results, desc=\"Saving documents\"):\n",
    "#         json.dump(item['_source'], f, default=json_serial)\n",
    "#         f.write('\\n')\n",
    "\n",
    "# print(\"Index backup completed and saved to 'lego_sets_backup.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixJSON(input_dict):\n",
    "    \"\"\"\n",
    "    Fixes a dictionary containing JSON-like strings and returns a dictionary with properly parsed JSON.\n",
    "    \n",
    "    Args:\n",
    "    input_dict (dict): A dictionary where values are JSON strings representing lists of questions.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with the same keys, but values parsed into lists of questions.\n",
    "    \"\"\"\n",
    "    def parse_value(value):\n",
    "        if isinstance(value, str):\n",
    "            try:\n",
    "                # Try to parse the string as JSON\n",
    "                parsed = json.loads(value)\n",
    "                # Ensure the parsed result is a list\n",
    "                if isinstance(parsed, list):\n",
    "                    return parsed\n",
    "                else:\n",
    "                    return [value]  # If not a list, wrap the original string in a list\n",
    "            except json.JSONDecodeError:\n",
    "                # If it's not valid JSON, return the original string wrapped in a list\n",
    "                return [value]\n",
    "        else:\n",
    "            # For any other type, return as is\n",
    "            return value\n",
    "\n",
    "    return {key: parse_value(value) for key, value in input_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = fixJSON(ground_truth_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth):\n",
    "    relevance_total = []\n",
    "\n",
    "    for setID, questions in tqdm(ground_truth.items()):\n",
    "        for question in questions:\n",
    "            results = elastic_search_vector(question)\n",
    "            ids = map(lambda x: x[\"setID\"], results)\n",
    "            relevance = [str(d['setID']) == setID for d in results]\n",
    "            relevance_total.append(relevance)\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8df5f318eed42d9a49e7994aecf0eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.676, 'mrr': 0.5139198257298251}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
